{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torch.autograd import Variable\n",
    "from torch.backends import cudnn\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Augmenting library \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import albumentations as A\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Control Randomness\n",
    "import random\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2, 3\"\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "\n",
    "# logging\n",
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joint_transforms\n",
    "from config import cod_training_root\n",
    "from config import backbone_path\n",
    "from datasets import ImageFolder\n",
    "from misc import AvgMeter, check_mkdir\n",
    "from PFNet import PFNet\n",
    "from helper import *\n",
    "import loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = './ckpt'\n",
    "exp_name = 'PFNet'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args = {\n",
    "    'epoch_num': 200,\n",
    "    'train_batch_size': 32,\n",
    "    'last_epoch': 0,\n",
    "    'lr': 1e-4, \n",
    "    'lr_decay': 0.9,\n",
    "    'weight_decay': 1e-4,\n",
    "    'momentum': 0.9,\n",
    "    'snapshot': '',\n",
    "    'scale': 416, \n",
    "    'save_point': [],\n",
    "    'poly_train': False,\n",
    "    'optimizer': 'Adam',\n",
    "    'amp' : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    loss = (1 -   ( (2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth))  )\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "def soft_dice_loss(inputs, targets):\n",
    "        num = targets.size(0)\n",
    "        m1  = inputs.view(num,-1)\n",
    "        m2  = targets.view(num,-1)\n",
    "        intersection = (m1 * m2)\n",
    "        score = 2. * (intersection.sum(1)+1) / (m1.sum(1) + m2.sum(1)+1)\n",
    "        score = 1 - score.sum()/num\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "drop = 0.25\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=True)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if inplanes!= planes:\n",
    "            self.conv0 = conv3x3(inplanes,planes)\n",
    "\n",
    "        self.inplanes = inplanes\n",
    "        self.planes = planes\n",
    "\n",
    "        self.conv1 = conv3x3(planes, planes, stride)\n",
    "        #self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #self.conv2 = conv3x3(planes, planes)\n",
    "        #self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.drop = nn.Dropout2d(p=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.inplanes != self.planes:\n",
    "            x = self.conv0(x)\n",
    "            x = F.relu(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        #out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.drop(out)\n",
    "\n",
    "        out1 = self.conv1(out)\n",
    "        #out1 = self.relu(out1)\n",
    "\n",
    "        out2 = out1 + x\n",
    "\n",
    "        return F.relu(out2)\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Initial_LadderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,planes,layers,kernel=3,block=BasicBlock,inplanes = 3):\n",
    "        super().__init__()\n",
    "        self.planes = planes\n",
    "        self.layers = layers\n",
    "        self.kernel = kernel\n",
    "\n",
    "        self.padding = int((kernel-1)/2)\n",
    "        self.inconv = nn.Conv2d(in_channels=inplanes,out_channels=planes,\n",
    "                                kernel_size=3,stride=1,padding=1,bias=True)\n",
    "\n",
    "        # create module list for down branch\n",
    "        self.down_module_list = nn.ModuleList()\n",
    "        for i in range(0,layers):\n",
    "            self.down_module_list.append(block(planes*(2**i),planes*(2**i)))\n",
    "\n",
    "        # use strided conv instead of poooling\n",
    "        self.down_conv_list = nn.ModuleList()\n",
    "        for i in range(0,layers):\n",
    "            self.down_conv_list.append(nn.Conv2d(planes*2**i,planes*2**(i+1),stride=2,kernel_size=kernel,padding=self.padding))\n",
    "\n",
    "        # create module for bottom block\n",
    "        self.bottom = block(planes*(2**layers),planes*(2**layers))\n",
    "\n",
    "        # create module list for up branch\n",
    "        self.up_conv_list = nn.ModuleList()\n",
    "        self.up_dense_list = nn.ModuleList()\n",
    "        for i in range(0, layers):\n",
    "            self.up_conv_list.append(nn.ConvTranspose2d(in_channels=planes*2**(layers-i), out_channels=planes*2**max(0,layers-i-1), kernel_size=3,\n",
    "                                                        stride=2,padding=1,output_padding=1,bias=True))\n",
    "            self.up_dense_list.append(block(planes*2**max(0,layers-i-1),planes*2**max(0,layers-i-1)))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.inconv(x)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        down_out = []\n",
    "        # down branch\n",
    "        for i in range(0,self.layers):\n",
    "            out = self.down_module_list[i](out)\n",
    "            down_out.append(out)\n",
    "            out = self.down_conv_list[i](out)\n",
    "            out = F.relu(out)\n",
    "\n",
    "        # bottom branch\n",
    "        out = self.bottom(out)\n",
    "        bottom = out\n",
    "\n",
    "        # up branch\n",
    "        up_out = []\n",
    "        up_out.append(bottom)\n",
    "\n",
    "        for j in range(0,self.layers):\n",
    "            out = self.up_conv_list[j](out) + down_out[self.layers-j-1]\n",
    "            #out = F.relu(out)\n",
    "            out = self.up_dense_list[j](out)\n",
    "            up_out.append(out)\n",
    "\n",
    "        return up_out\n",
    "\n",
    "class LadderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,planes,layers,kernel=3,block=BasicBlock,inplanes = 3):\n",
    "        super().__init__()\n",
    "        self.planes = planes\n",
    "        self.layers = layers\n",
    "        self.kernel = kernel\n",
    "\n",
    "        self.padding = int((kernel-1)/2)\n",
    "        self.inconv = block(planes,planes)\n",
    "\n",
    "        # create module list for down branch\n",
    "        self.down_module_list = nn.ModuleList()\n",
    "        for i in range(0,layers):\n",
    "            self.down_module_list.append(block(planes*(2**i),planes*(2**i)))\n",
    "\n",
    "        # use strided conv instead of poooling\n",
    "        self.down_conv_list = nn.ModuleList()\n",
    "        for i in range(0,layers):\n",
    "            self.down_conv_list.append(nn.Conv2d(planes*2**i,planes*2**(i+1),stride=2,kernel_size=kernel,padding=self.padding))\n",
    "\n",
    "        # create module for bottom block\n",
    "        self.bottom = block(planes*(2**layers),planes*(2**layers))\n",
    "\n",
    "        # create module list for up branch\n",
    "        self.up_conv_list = nn.ModuleList()\n",
    "        self.up_dense_list = nn.ModuleList()\n",
    "        for i in range(0, layers):\n",
    "            self.up_conv_list.append(nn.ConvTranspose2d(planes*2**(layers-i), planes*2**max(0,layers-i-1), kernel_size=3,\n",
    "                                                        stride=2,padding=1,output_padding=1,bias=True))\n",
    "            self.up_dense_list.append(block(planes*2**max(0,layers-i-1),planes*2**max(0,layers-i-1)))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.inconv(x[-1])\n",
    "\n",
    "        down_out = []\n",
    "        # down branch\n",
    "        for i in range(0,self.layers):\n",
    "            out = out + x[-i-1]\n",
    "            out = self.down_module_list[i](out)\n",
    "            down_out.append(out)\n",
    "\n",
    "            out = self.down_conv_list[i](out)\n",
    "            out = F.relu(out)\n",
    "\n",
    "        # bottom branch\n",
    "        out = self.bottom(out)\n",
    "        bottom = out\n",
    "\n",
    "        # up branch\n",
    "        up_out = []\n",
    "        up_out.append(bottom)\n",
    "\n",
    "        for j in range(0,self.layers):\n",
    "            out = self.up_conv_list[j](out) + down_out[self.layers-j-1]\n",
    "            #out = F.relu(out)\n",
    "            out = self.up_dense_list[j](out)\n",
    "            up_out.append(out)\n",
    "\n",
    "        return up_out\n",
    "\n",
    "\n",
    "class Final_LadderBlock(nn.Module):\n",
    "\n",
    "    def __init__(self,planes,layers,kernel=3,block=BasicBlock,inplanes = 3):\n",
    "        super().__init__()\n",
    "        self.block = LadderBlock(planes,layers,kernel=kernel,block=block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out[-1]\n",
    "\n",
    "\n",
    "def cuda(x):\n",
    "    return x.cuda() if torch.cuda.is_available() else x\n",
    "\n",
    "class LossMulti:\n",
    "    def __init__(self, jaccard_weight=0, class_weights=None, num_classes=1):\n",
    "        if class_weights is not None:\n",
    "            nll_weight = cuda(\n",
    "                torch.from_numpy(class_weights.astype(np.float32)))\n",
    "        else:\n",
    "            nll_weight = None\n",
    "        self.nll_loss = nn.NLLLoss2d(weight=nll_weight)\n",
    "        self.jaccard_weight = jaccard_weight\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __call__(self, outputs, targets):\n",
    "        loss = (1 - self.jaccard_weight) * self.nll_loss(outputs, targets)\n",
    "\n",
    "        if self.jaccard_weight:\n",
    "            eps = 1e-15\n",
    "            for cls in range(self.num_classes):\n",
    "                jaccard_target = (targets == cls).float()\n",
    "                jaccard_output = outputs[:, cls].exp()\n",
    "                intersection = (jaccard_output * jaccard_target).sum()\n",
    "\n",
    "                union = jaccard_output.sum() + jaccard_target.sum()\n",
    "                loss -= torch.log((intersection + eps) / (union - intersection + eps)) * self.jaccard_weight\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LadderNetv6(nn.Module):\n",
    "    def __init__(self,layers=3,filters=16,num_classes=1,inplanes=3):\n",
    "        super().__init__()\n",
    "        self.initial_block = Initial_LadderBlock(planes=filters,layers=layers,inplanes=inplanes)\n",
    "        #self.middle_block = LadderBlock(planes=filters,layers=layers)\n",
    "        self.final_block = Final_LadderBlock(planes=filters,layers=layers)\n",
    "        self.final = nn.Conv2d(in_channels=filters,out_channels=num_classes,kernel_size=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.initial_block(x)\n",
    "        #out = self.middle_block(out)\n",
    "        out = self.final_block(out)\n",
    "        out = self.final(out)\n",
    "        #out = F.relu(out)\n",
    "        out = F.log_softmax(out,dim=1)\n",
    "        # out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = LadderNetv6()\n",
    "criterion = LossMulti(jaccard_weight=0)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=args['lr'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=40, verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making data index list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_files = os.walk(\"/home/sklab2/workspace/datashared/SS-OCT/vessel_segmentation/masked\")\n",
    "mask_idx = []\n",
    "for (root, dirs, files) in mask_files:\n",
    "    if len(files) > 0 :\n",
    "        mask_idx.append(files)\n",
    "\n",
    "mask_idxs = [element for array in mask_idx for element in array]\n",
    "len(mask_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1~ 11 / 12, 13, 14  , 40, 41, 43, 44, 46, 49,  50, 53, 54, 55 \n",
    "train_indexs = []\n",
    "test_indexs = []\n",
    "for idx, data in enumerate(mask_idxs):\n",
    "    tmp = mask_idxs[idx].split('_')\n",
    "    if len(tmp) < 3:\n",
    "        if int(tmp[0]) < 45:\n",
    "            train_indexs.append([ tmp[0], tmp[1].split('.')[0]])\n",
    "        else:\n",
    "            test_indexs.append([tmp[0], tmp[1].split('.')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_indexs) , len(test_indexs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations.augmentations.functional as AF\n",
    "\n",
    "PATH = '/home/sklab2/workspace/datashared/SS-OCT/vessel_segmentation/'\n",
    "class VesselDataset(Dataset):\n",
    "    def __init__(self, index, transforms):\n",
    "        self.index = index\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        s_1 = self.index[idx][0]\n",
    "        s_2 = self.index[idx][1]\n",
    "\n",
    "        # '1_L_0.jpg', \n",
    "        image = Image.open(PATH+'origin/' + s_1+'_L_'+s_2+'.jpg').resize((416, 416),Image.Resampling.BILINEAR)\n",
    "        #'10_L_112_L.png', \n",
    "        mask = Image.open(PATH+'masked/' +  s_1+'_'+s_2+'.png').resize((416, 416),Image.Resampling.BILINEAR)\n",
    "        \n",
    "        image = np.array(image, dtype=np.uint8) #RGB\n",
    "        mask = np.array(mask, dtype=np.uint8)   # HWC\n",
    "        mask_o = mask / 255        # CHW\n",
    "\n",
    "        lower_red = np.array([-10, 100, 100]) \n",
    "        upper_red = np.array([10, 255, 255]) \n",
    "\n",
    "        mask_hsv = cv2.cvtColor(mask, cv2.COLOR_RGB2HSV)\n",
    "        mask = cv2.inRange(mask_hsv, lower_red, upper_red)\n",
    "\n",
    "        aft_mask = mask / 255\n",
    "        \n",
    "        # aft_mask = cv2.resize(aft_mask, (416, 416), interpolation=cv2.INTER_NEAREST)\n",
    "        masks = [aft_mask, mask_o]  # target, original\n",
    "\n",
    "        # for num in range(3): #### 3번 이터레이션이 왜들어갔지?\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image, masks=masks)\n",
    "            image, masks = transformed['image'], transformed['masks']\n",
    "        # urls.append(s_1+'_'+s_2)\n",
    "        assert sum(masks[0]==0).sum() + sum(masks[0]==1).sum() == 416*416   # mask가 0 또는 1이 아닐경우 스탑\n",
    "                    \n",
    "        return image, masks, aft_mask, s_1+'_'+s_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations.pytorch as AP\n",
    "\n",
    "# def get_mean_std(dataset):\n",
    "#     meanRGB = [np.mean(image.numpy(), axis=(1, 2)) for image, _, _, _ in dataset]\n",
    "#     stdRGB = [np.std(image.numpy(), axis=(1, 2)) for image, _, _, _ in dataset]\n",
    "\n",
    "#     meanR = np.mean([m[0] for m in meanRGB])\n",
    "#     meanG = np.mean([m[1] for m in meanRGB])\n",
    "#     meanB = np.mean([m[2] for m in meanRGB])\n",
    "\n",
    "#     stdR = np.mean([s[0] for s in stdRGB])\n",
    "#     stdG = np.mean([s[1] for s in stdRGB])\n",
    "#     stdB = np.mean([s[2] for s in stdRGB])\n",
    "\n",
    "#     print(meanR, meanG, meanB)\n",
    "#     print(stdR, stdG, stdB)\n",
    "\n",
    "#     return meanRGB, stdRGB\n",
    "\n",
    "def get_mean_std(dataset):\n",
    "    mean_ = [np.mean(image.numpy(), axis=(1, 2)) for image, _, _, _ in dataset]\n",
    "    std_ = [np.std(image.numpy(), axis=(1, 2)) for image, _, _, _ in dataset]\n",
    "\n",
    "    mean = np.mean(mean_)\n",
    "    std = np.mean(std_)\n",
    "\n",
    "    print(mean, std)\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    # A.Resize(416, 416, interpolation=cv2.INTER_NEAREST),\n",
    "    # A.RandomRotate90(p=prob),\n",
    "    # A.HorizontalFlip(p=prob),\n",
    "    # A.OneOf([\n",
    "    #     A.OpticalDistortion(p=1, distort_limit=0.1, interpolation=cv2.INTER_NEAREST),\n",
    "    #     A.GridDistortion(p=1, interpolation=cv2.INTER_NEAREST),\n",
    "    #     A.ElasticTransform(p=1, interpolation=cv2.INTER_NEAREST),\n",
    "    #     ], p = prob),\n",
    "    # A.RandomBrightnessContrast(p=prob),    # 밝기 및 조도 변화\n",
    "    # A.Normalize(mean=(126.71482973095203, 126.6879562017254, 126.85466873988524), std = (31.31187149184309, 31.37091519475967, 31.28646507868047)),\n",
    "    AP.ToTensorV2(always_apply=True)\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    AP.ToTensorV2(always_apply=True)\n",
    "])\n",
    "\n",
    "# tensor([127.5388, 127.5482, 127.6733])\n",
    "# tensor([57.4250, 57.6999, 57.5387])\n",
    "train_dataset = VesselDataset(index=train_indexs, transforms=train_transform)\n",
    "test_dataset = VesselDataset(index=test_indexs, transforms=test_transform)\n",
    " \n",
    "#train_dataset, _, test_dataset = torch.utils.data.random_split(dataset, [train, 0, test])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=args['train_batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "image, masks, aft_mask, _= next(iter(train_loader))\n",
    "print(image.shape, masks[0].shape, masks[1].shape, aft_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
    "def calc_metric(labels, preds):\n",
    "    accuracy = np.mean(np.equal(labels,preds))\n",
    "    right = np.sum(labels *preds == 1)\n",
    "    precision = right / np.sum(preds)\n",
    "    recall = right / np.sum(labels)\n",
    "    f1 = 2 * precision*recall/(precision+recall)\n",
    "\n",
    "    \n",
    "    y_pred = preds\n",
    "    y_true = labels\n",
    "    \"\"\" Ground truth \"\"\"\n",
    "    #y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    #y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    score_jaccard = jaccard_score(y_true, y_pred)\n",
    "    score_f1 = f1_score(y_true, y_pred)\n",
    "    score_recall = recall_score(y_true, y_pred)\n",
    "    score_precision = precision_score(y_true, y_pred)\n",
    "    score_acc = accuracy_score(y_true, y_pred)\n",
    "    print('jaccard, f1, recall, precision, acc')\n",
    "    print(score_jaccard, score_f1, score_recall, score_precision, score_acc)\n",
    "    return score_jaccard, score_f1, score_recall, score_precision, score_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_pil_image(net(image[:4].float())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_pil_image(torchvision.utils.make_grid(image[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_pil_image(torchvision.utils.make_grid(aft_mask[:4].unsqueeze(1).expand(4, 3, 416, 416)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_pil_image(torchvision.utils.make_grid(masks[1][:4].permute(0, 3, 1, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import datetime \n",
    "\n",
    "exp = 'LadderNet'\n",
    "\n",
    "num_epochs = args['epoch_num']\n",
    "resume_epochs = args['last_epoch']\n",
    "load_from = '../model/vessel_PFNet_base_b32_e500_220921_00:30.pt'\n",
    "\n",
    "\n",
    "batch_size = args['train_batch_size']\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "now = datetime.datetime.now()\n",
    "log_name = f'{exp}_b{batch_size}_e{num_epochs}_js_'+now.strftime(\"%y%m%d_%H:%M\")\n",
    "writer = SummaryWriter(log_dir='./ckpt/PFNet/log/'+ log_name)\n",
    "save_path = f'../model/vessel_{exp}_b{batch_size}_e{num_epochs}_'+ now.strftime(\"%y%m%d_%H:%M\") + '.pt'\n",
    "\n",
    "\n",
    "print(f'Using {torch.cuda.device_count()} GPUs.')\n",
    "net = nn.DataParallel(net)\n",
    "\n",
    "# net.float()\n",
    "net = net.to(device)\n",
    "train_loss_list = []\n",
    "test_acc_list = []\n",
    "test_recall_list = []\n",
    "test_f1_list = []\n",
    "test_iou_list = []\n",
    "print(log_name)\n",
    "print(save_path)\n",
    "print(f'Training {num_epochs} epochs.')\n",
    "if resume_epochs != 0:\n",
    "    print(f'Resuming from epoch {resume_epochs}')\n",
    "    net.load_state_dict(torch.load(load_from))\n",
    "if args['amp'] == True:\n",
    "    print(\"Using mixed precision.\")\n",
    "\n",
    "# print(data.shape, aug_masks[0].shape, aug_masks[1].shape, aft_mask.shape)\n",
    "curr_iter = 1\n",
    "\n",
    "for epoch in range(args['last_epoch'], args['last_epoch'] + args['epoch_num']):\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "    loss_running = 0\n",
    "    tqdm_dataset = tqdm(train_loader)\n",
    "    for batch_idx, batch in enumerate(tqdm_dataset):\n",
    "        if args['poly_train']:\n",
    "            base_lr = args['lr'] * (1 - float(curr_iter) / float(num_epochs)) ** args['lr_decay']\n",
    "            optimizer.param_groups[0]['lr'] = 2 * base_lr\n",
    "            optimizer.param_groups[1]['lr'] = 1 * base_lr\n",
    "\n",
    "        image, masks, aft_mask, _ = batch\n",
    "\n",
    "        labels = masks[0]\n",
    "        labels = labels.unsqueeze(1)\n",
    "        image, labels = image.float().to(device), labels.float().to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "\n",
    "        outputs = net(image)\n",
    "        loss = dice_loss(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        # nn.utils.clip_grad_norm_(net.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_running += loss.item()\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch,\n",
    "            'Loss': '{:06f}'.format(loss.item()),\n",
    "            'Mean Loss' : '{:06f}'.format(loss_running/(batch_idx+1)),\n",
    "            'lr' : '{:06f}'.format(optimizer.param_groups[0][\"lr\"])\n",
    "        })\n",
    "\n",
    "        curr_iter += 1\n",
    "\n",
    "    epoch_loss = loss_running / len(train_loader)\n",
    "    # scheduler.step()\n",
    "\n",
    "    writer.add_scalar('loss/Train', epoch_loss, epoch)\n",
    "    writer.add_scalar('learning_rate', optimizer.param_groups[0][\"lr\"], epoch)\n",
    "    train_loss_list.append(epoch_loss)\n",
    "\n",
    "## EVAL\n",
    "    if epoch % 10 == 0 or epoch == args['epoch_num']-1 :\n",
    "        print(\"Testing...\")\n",
    "\n",
    "        images=[]\n",
    "        preds=[]\n",
    "        labels=[]\n",
    "        label_os = []\n",
    "        urls_list = []\n",
    "        net.eval()\n",
    "        # tqdm_loader = tqdm(test_loader)\n",
    "        with torch.no_grad():\n",
    "            for idx, dd in enumerate(test_loader):\n",
    "\n",
    "                image, masks, mask_o, urls = dd \n",
    "                \n",
    "                image = image.float().to(device)\n",
    "                label = masks[0].float()\n",
    "                label_o = masks[1].float()\n",
    "                pred = net(image)    \n",
    "\n",
    "                images.append(image.cpu().detach().numpy())\n",
    "                labels.append(label.numpy())\n",
    "                label_os.append(label_o)\n",
    "                preds.append(pred.cpu().detach().numpy())\n",
    "                urls_list.append(urls)\n",
    "\n",
    "            images= np.array(images).squeeze(1)\n",
    "            preds = np.array(preds).squeeze(1)\n",
    "            labels = np.array(labels)\n",
    "            label_os = np.array(label_os)\n",
    "            preds = np.where(preds > 0.5 , 1 , 0)\n",
    "            labels = np.where(labels > 0.5 , 1 , 0)\n",
    "            \n",
    "            score_jaccard, score_f1, score_recall, score_precision, score_acc = calc_metric(labels=labels, preds=preds)\n",
    "            test_acc_list.append(score_acc)\n",
    "            test_recall_list.append(score_recall)\n",
    "            test_f1_list.append(score_f1)\n",
    "            test_iou_list.append(score_jaccard)\n",
    "            writer.add_scalar('Accuracy/Test', score_acc, epoch)\n",
    "            writer.add_scalar('F1/Test', score_f1, epoch)\n",
    "            writer.add_scalar('Recall/Test', score_recall, epoch)\n",
    "            writer.add_scalar('Precision/Test', score_precision, epoch)\n",
    "            writer.add_scalar('Jaccard/Test', score_jaccard, epoch)\n",
    "\n",
    "            if np.max(test_iou_list) == test_iou_list[-1] or np.max(test_f1_list) == test_f1_list[-1]:\n",
    "                torch.save(net.state_dict(), save_path)\n",
    "                print(\"Model Saved\")\n",
    "\n",
    "            randnum = np.random.randint(0, 171)\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.subplot(1, 3, 1)  \n",
    "            plt.imshow(label_os[randnum][0])\n",
    "            plt.subplot(1, 3, 2)  \n",
    "            plt.imshow(labels[randnum][0])\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(preds[randnum][0])\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing...\")\n",
    "net = SA_UNet(in_channels=3, num_classes=1 , base_c=16)\n",
    "load_from = '/home/sklab2/workspace/code_only/junsu/model/vessel_SA_Unet_b32_e200_220930_15:31.pt'\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f'Using {torch.cuda.device_count()} GPUs.')\n",
    "net = nn.DataParallel(net)\n",
    "net.load_state_dict(torch.load(load_from))\n",
    "net.to(device)\n",
    "\n",
    "images=[]\n",
    "preds=[]\n",
    "labels=[]\n",
    "label_os = []\n",
    "urls_list = []\n",
    "net.eval()\n",
    "# tqdm_loader = tqdm(test_loader)\n",
    "with torch.no_grad():\n",
    "    for idx, dd in enumerate(tqdm(test_loader)):\n",
    "\n",
    "        image, masks, mask_o, _ = dd \n",
    "        \n",
    "        image = image.float().to(device)\n",
    "        label = masks[0].float()\n",
    "        label_o = masks[1].float()\n",
    "        pred = net(image)    \n",
    "\n",
    "        images.append(image.cpu().detach().numpy())\n",
    "        labels.append(label.numpy())\n",
    "        label_os.append(label_o)\n",
    "        preds.append(pred.cpu().detach().numpy())\n",
    "        urls_list.append(urls)\n",
    "\n",
    "    images= np.array(images).squeeze(1)\n",
    "    preds = np.array(preds).squeeze(1)\n",
    "    labels = np.array(labels)\n",
    "    label_os = np.array(label_os)\n",
    "    preds = np.where(preds > 0.5 , 1 , 0)\n",
    "    labels = np.where(labels > 0.5 , 1 , 0)\n",
    "    \n",
    "    score_jaccard, score_f1, score_recall, score_precision, score_acc = calc_metric(labels=labels, preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# randnum = np.random.randint(0, len(test_dataset)-10)\n",
    "randnum=211\n",
    "\n",
    "fig, axes = plt.subplots(10, 3, figsize = (10,40))\n",
    "[c_ax.axis('off') for c_ax in axes.flatten()]\n",
    "\n",
    "for idx, (img_ax, target_ax , mask_ax ) in zip(range(randnum, randnum+10), axes):\n",
    "    \n",
    "# inputs[:10] , preds[:10], targets[:10], urls_list[:10]) :\n",
    "    \n",
    "    image = images[idx].astype(int).transpose(1, 2, 0) # astype(int)\n",
    "    img_target = preds[idx].transpose(1, 2, 0) \n",
    "    img_mask = labels[idx].transpose(1, 2, 0)  \n",
    " \n",
    "    img_ax.imshow(np.clip(image, 0, 255))\n",
    "\n",
    "    target_ax.imshow(img_target )\n",
    "    mask_ax.imshow(img_mask)\n",
    "\n",
    "    img_ax.set_title(f'  testing: {idx}')\n",
    "    target_ax.set_title(f' Predicted : {idx}')\n",
    "    \n",
    "    mask_ax.set_title(f' target   vessel: {idx}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8128ea53b667df2c63505870f2ff8004b9270a6bef27cafea1d8458469672f96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
