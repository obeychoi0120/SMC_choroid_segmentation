{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torch.autograd import Variable\n",
    "from torch.backends import cudnn\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Augmenting library \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import albumentations as A\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Control Randomness\n",
    "import random\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "\n",
    "# logging\n",
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joint_transforms\n",
    "from config import cod_training_root\n",
    "from config import backbone_path\n",
    "from datasets import ImageFolder\n",
    "from misc import AvgMeter, check_mkdir\n",
    "from PFNet import PFNet\n",
    "from helper import *\n",
    "import loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = './ckpt'\n",
    "exp_name = 'PFNet'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args = {\n",
    "    'epoch_num': 200,\n",
    "    'train_batch_size': 32,\n",
    "    'last_epoch': 0,\n",
    "    'lr': 1e-4, \n",
    "    'lr_decay': 0.9,\n",
    "    'weight_decay': 5e-4,\n",
    "    'momentum': 0.9,\n",
    "    'snapshot': '',\n",
    "    'scale': 416, \n",
    "    'save_point': [],\n",
    "    'poly_train': False,\n",
    "    'optimizer': 'Adam',\n",
    "    'amp' : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "structure_loss = loss.structure_loss().to(device)\n",
    "bce_loss = nn.BCEWithLogitsLoss().to(device)\n",
    "iou_loss = loss.IOU().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_iou_loss(pred, target):\n",
    "    bce_out = bce_loss(pred, target)\n",
    "    iou_out = iou_loss(pred, target)\n",
    "    loss = bce_out + iou_out\n",
    "    return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From ./backbone/resnet/resnet50-19c8e357.pth Load resnet50 Weights Succeed!\n"
     ]
    }
   ],
   "source": [
    "net = PFNet(backbone_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adam opt\n"
     ]
    }
   ],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "if args['optimizer'] == 'SGD':\n",
    "    print('SGD opt')\n",
    "    optimizer = torch.optim.SGD([\n",
    "        {'params': [param for name, param in net.named_parameters() if name[-4:] == 'bias'],\n",
    "        'lr': 2 * args['lr']},\n",
    "        {'params': [param for name, param in net.named_parameters() if name[-4:] != 'bias'],\n",
    "        'lr': 1 * args['lr'], 'weight_decay': args['weight_decay']}\n",
    "    ], momentum=args['momentum'])\n",
    "\n",
    "else:\n",
    "    print('Adam opt')\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': [param for name, param in net.named_parameters() if name[-4:] == 'bias'],\n",
    "            'lr': 2 * args['lr']},\n",
    "        {'params': [param for name, param in net.named_parameters() if name[-4:] != 'bias'],\n",
    "            'lr': 1 * args['lr'], 'weight_decay': args['weight_decay']}\n",
    "    ])\n",
    "\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, \\\n",
    "#                                 threshold=0.05, threshold_mode='rel', cooldown=5, min_lr = 1e-4)\n",
    "\n",
    "# scheduler = CosineAnnealingWarmupRestarts(optimizer, first_cycle_steps=200, cycle_mult=1.0, max_lr=0.1, min_lr=0.001, warmup_steps=50, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making data index list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_files = os.walk(\"/home/sklab2/workspace/datashared/SS-OCT/vessel_segmentation/exp/masked\")\n",
    "# mask_idx = []\n",
    "# for (root, dirs, files) in mask_files:\n",
    "#     if len(files) > 0 :\n",
    "#         mask_idx.append(files)\n",
    "\n",
    "# mask_idxs = [element for array in mask_idx for element in array]\n",
    "# len(mask_idxs)\n",
    "\n",
    "# # 1~ 11 / 12, 13, 14  , 40, 41, 43, 44, 46, 49,  50, 53, 54, 55 \n",
    "# train_indexs = []\n",
    "# test_indexs = []\n",
    "# for idx, data in enumerate(mask_idxs):\n",
    "#     tmp = mask_idxs[idx].split('_')\n",
    "#     test_indexs.append([tmp[0], tmp[1].split('.')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_files = os.walk(\"/home/sklab2/workspace/datashared/SS-OCT/vessel_segmentation/masked\")\n",
    "mask_idx = []\n",
    "for (root, dirs, files) in mask_files:\n",
    "    if len(files) > 0 :\n",
    "        mask_idx.append(files)\n",
    "\n",
    "mask_idxs = [element for array in mask_idx for element in array]\n",
    "\n",
    "# 1~ 11 / 12, 13, 14  , 40, 41, 43, 44, 46, 49,  50, 53, 54, 55 \n",
    "train_indexs = []\n",
    "test_indexs = []\n",
    "for idx, data in enumerate(mask_idxs):\n",
    "    tmp = mask_idxs[idx].split('_')\n",
    "    if len(tmp) < 3:\n",
    "        if int(tmp[0]) < 45:\n",
    "            train_indexs.append([ tmp[0], tmp[1].split('.')[0]])\n",
    "        else:\n",
    "            test_indexs.append([tmp[0], tmp[1].split('.')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['46', '21']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_indexs[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import albumentations.augmentations.functional as AF\n",
    "\n",
    "# PATH = '/home/sklab2/workspace/datashared/SS-OCT/vessel_segmentation/exp/'\n",
    "# class VesselDataset(Dataset):\n",
    "#     def __init__(self, index, transforms):\n",
    "#         self.index = index\n",
    "#         self.transforms = transforms\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.index)\n",
    "        \n",
    "#     def __getitem__(self, idx):\n",
    "#         s_1 = self.index[idx][0]\n",
    "#         s_2 = self.index[idx][1]\n",
    "\n",
    "#         # '1_L_0.jpg', \n",
    "#         image = Image.open(PATH+'origin/' + s_1+'_'+s_2+'.jpg').resize((416, 416),Image.Resampling.BILINEAR)\n",
    "#         #'10_L_112_L.png', \n",
    "#         mask = Image.open(PATH+'masked/' +  s_1+'_'+s_2+'.png').resize((416, 416),Image.Resampling.BILINEAR)\n",
    "        \n",
    "#         image = np.array(image, dtype=np.uint8) #RGB\n",
    "#         mask = np.array(mask, dtype=np.uint8)   # HWC\n",
    "#         mask_o = mask / 255        # CHW\n",
    "\n",
    "\n",
    "#         lower_red = np.array([-10, 100, 100]) \n",
    "#         upper_red = np.array([10, 255, 255]) \n",
    "\n",
    "#         mask_hsv = cv2.cvtColor(mask, cv2.COLOR_RGB2HSV)\n",
    "#         mask = cv2.inRange(mask_hsv, lower_red, upper_red)\n",
    "\n",
    "#         aft_mask = mask / 255\n",
    "        \n",
    "#         # aft_mask = cv2.resize(aft_mask, (416, 416), interpolation=cv2.INTER_NEAREST)\n",
    "#         masks = [aft_mask, mask_o]  # target, original\n",
    "\n",
    "#         # for num in range(3): #### 3번 이터레이션이 왜들어갔지?\n",
    "#         if self.transforms:\n",
    "#             transformed = self.transforms(image=image, masks=masks)\n",
    "#             image, masks = transformed['image'], transformed['masks']\n",
    "#         # urls.append(s_1+'_'+s_2)\n",
    "#         assert sum(masks[0]==0).sum() + sum(masks[0]==1).sum() == 416*416   # mask가 0 또는 1이 아닐경우 스탑\n",
    "                    \n",
    "#         return image, masks, aft_mask, s_1+'_'+s_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "import albumentations.augmentations.functional as AF\n",
    "\n",
    "PATH = '/home/sklab2/workspace/datashared/SS-OCT/vessel_segmentation/'\n",
    "class VesselDataset(Dataset):\n",
    "    def __init__(self, index, transforms):\n",
    "        self.index = index\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        s_1 = self.index[idx][0]\n",
    "        s_2 = self.index[idx][1]\n",
    "\n",
    "        # '1_L_0.jpg', \n",
    "        image = Image.open(PATH+'origin/' + s_1+'_L_'+s_2+'.jpg').resize((416, 416),Image.Resampling.BILINEAR)\n",
    "        #'10_L_112_L.png', \n",
    "        mask = Image.open(PATH+'masked/' +  s_1+'_'+s_2+'.png').resize((416, 416),Image.Resampling.BILINEAR)\n",
    "        \n",
    "        image = np.array(image, dtype=np.uint8) #RGB\n",
    "        mask = np.array(mask, dtype=np.uint8)   # HWC\n",
    "        mask_o = mask / 255        # CHW\n",
    "\n",
    "\n",
    "        lower_red = np.array([-10, 100, 100]) \n",
    "        upper_red = np.array([10, 255, 255]) \n",
    "\n",
    "        mask_hsv = cv2.cvtColor(mask, cv2.COLOR_RGB2HSV)\n",
    "        mask = cv2.inRange(mask_hsv, lower_red, upper_red)\n",
    "\n",
    "        aft_mask = mask / 255\n",
    "        \n",
    "        # aft_mask = cv2.resize(aft_mask, (416, 416), interpolation=cv2.INTER_NEAREST)\n",
    "        masks = [aft_mask, mask_o]  # target, original\n",
    "\n",
    "        # for num in range(3): #### 3번 이터레이션이 왜들어갔지?\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image, masks=masks)\n",
    "            image, masks = transformed['image'], transformed['masks']\n",
    "        # urls.append(s_1+'_'+s_2)\n",
    "        assert sum(masks[0]==0).sum() + sum(masks[0]==1).sum() == 416*416   # mask가 0 또는 1이 아닐경우 스탑\n",
    "                    \n",
    "        return image, masks, aft_mask, s_1+'_'+s_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [59], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mtest_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# image, [mask_r, mask_y, mask_o] =next(iter(train_loader))\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m image,[mask_r, mask_y], mask_o \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(train_loader))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(image\u001b[38;5;241m.\u001b[39mshape, mask_r\u001b[38;5;241m.\u001b[39mshape, mask_y\u001b[38;5;241m.\u001b[39mshape, mask_o\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import albumentations.pytorch as AP\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.RandomRotate90(p=0.25),\n",
    "    A.RandomResizedCrop(416, 416, scale=(0.5, 1.0), ratio=(0.8, 1.2), interpolation=cv2.INTER_AREA, p=0.25),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(p=1, interpolation=cv2.INTER_AREA),\n",
    "        A.GridDistortion(p=1, interpolation=cv2.INTER_AREA),\n",
    "        A.ElasticTransform(p=1, alpha=100, sigma=100 * 0.05, alpha_affine=100 * 0.03, interpolation=cv2.INTER_AREA)\n",
    "        ], p = 0.5),  # 밝기 및 조도 변화\n",
    "    # A.Normalize(mean=(126.71482973095203, 126.6879562017254, 126.85466873988524), std = (32.9434, 33.0122, 32.9186)),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n",
    "    AP.ToTensorV2(transpose_mask=False),\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    AP.ToTensorV2(always_apply=True)\n",
    "])\n",
    "\n",
    "# tensor([127.5388, 127.5482, 127.6733])\n",
    "# tensor([57.4250, 57.6999, 57.5387])\n",
    "train_dataset = VesselDataset(index=train_indexs, transforms=train_transform)\n",
    "test_dataset = VesselDataset(index=test_indexs, transforms=test_transform)\n",
    " \n",
    "#train_dataset, _, test_dataset = torch.utils.data.random_split(dataset, [train, 0, test])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=args['train_batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "image, masks, aft_mask, _= next(iter(train_loader))\n",
    "print(image.shape, masks[0].shape, masks[1].shape, aft_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_pil_image(torchvision.utils.make_grid(image[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_pil_image(torchvision.utils.make_grid(mask_o[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score, precision_score, recall_score\n",
    "def calc_metric(labels, preds):\n",
    "    accuracy = np.mean(np.equal(labels,preds))\n",
    "    right = np.sum(labels *preds == 1)\n",
    "    precision = right / np.sum(preds)\n",
    "    recall = right / np.sum(labels)\n",
    "    f1 = 2 * precision*recall/(precision+recall)\n",
    "\n",
    "    \n",
    "    y_pred = preds\n",
    "    y_true = labels\n",
    "    \"\"\" Ground truth \"\"\"\n",
    "    #y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    #y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    score_jaccard = jaccard_score(y_true, y_pred)\n",
    "\n",
    "    print('jaccard, f1, recall, precision, acc')\n",
    "    print(score_jaccard, f1, recall, precision, accuracy)\n",
    "    return score_jaccard, f1, recall, precision, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing...\")\n",
    "net = PFNet(backbone_path)\n",
    "load_from = '/home/sklab2/workspace/code_only/junsu/model/vessel_PFNet_base_b32_e200_220930_22:41.pt'\n",
    "# load_from = '/home/sklab2/workspace/code_only/junsu/model/vessel_PFNet_aug50+focal+coslr_b32_e300_220928_01:55.pt'\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f'Using {torch.cuda.device_count()} GPUs.')\n",
    "net = nn.DataParallel(net)\n",
    "net.load_state_dict(torch.load(load_from))\n",
    "net.to(device)\n",
    "\n",
    "images=[]\n",
    "preds=[]\n",
    "labels=[]\n",
    "label_os = []\n",
    "urls_list = []\n",
    "net.eval()\n",
    "# tqdm_loader = tqdm(test_loader)\n",
    "with torch.no_grad():\n",
    "    for idx, dd in enumerate(tqdm(test_loader)):\n",
    "\n",
    "        image, masks, mask_o, urls = dd \n",
    "        \n",
    "        image = image.float().to(device)\n",
    "        label = masks[0].float()\n",
    "        label_o = masks[1].float()\n",
    "        _, _, _, pred = net(image)    \n",
    "\n",
    "        images.append(image.cpu().detach().numpy())\n",
    "        labels.append(label.numpy())\n",
    "        label_os.append(label_o)\n",
    "        preds.append(pred.cpu().detach().numpy())\n",
    "        urls_list.append(urls)\n",
    "\n",
    "    images= np.array(images).squeeze(1)\n",
    "    preds = np.array(preds).squeeze(1)\n",
    "    labels = np.array(labels)\n",
    "    label_os = np.array(label_os)\n",
    "    preds = np.where(preds > 0.5 , 1 , 0)\n",
    "    labels = np.where(labels > 0.5 , 1 , 0)\n",
    "    \n",
    "    # score_jaccard, score_f1, score_recall, score_precision, score_acc = calc_metric(labels=labels, preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# randnum = np.random.randint(0, len(test_dataset)-10)\n",
    "randnum=218\n",
    "\n",
    "fig, axes = plt.subplots(10, 4, figsize = (12,36))\n",
    "[c_ax.axis('off') for c_ax in axes.flatten()]\n",
    "\n",
    "for idx, (img_ax, pred_ax, target_ax ,mask_o_ax) in zip(range(randnum, randnum+10), axes):\n",
    "    \n",
    "# inputs[:10] , preds[:10], targets[:10], urls_list[:10]) :\n",
    "    \n",
    "    image = images[idx].astype(int).transpose(1, 2, 0) # astype(int)\n",
    "    img_pred = preds[idx].transpose(1, 2, 0) \n",
    "    img_mask = labels[idx].transpose(1, 2, 0)\n",
    "    img_mask_o = label_os[idx][0]\n",
    " \n",
    "    img_ax.imshow(np.clip(image, 0, 255))\n",
    "    mask_o_ax.imshow(img_mask_o)\n",
    "    target_ax.imshow(img_mask)\n",
    "    pred_ax.imshow(img_pred)\n",
    "\n",
    "\n",
    "    img_ax.set_title(f'Test num: {idx}')\n",
    "    mask_o_ax.set_title(f'Annotation: {idx}')\n",
    "    target_ax.set_title(f'Ground Truth: {idx}')\n",
    "    pred_ax.set_title(f'Predicted: {idx}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8128ea53b667df2c63505870f2ff8004b9270a6bef27cafea1d8458469672f96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
