{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "from torch.autograd import Variable\n",
    "from torch.backends import cudnn\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Augmenting library \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "import albumentations as A\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Control Randomness\n",
    "import random\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "\n",
    "# logging\n",
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joint_transforms\n",
    "from config import cod_training_root\n",
    "from config import backbone_path\n",
    "from datasets import ImageFolder\n",
    "from misc import AvgMeter, check_mkdir\n",
    "from PFNet import PFNet\n",
    "from helper import FocalLoss, CosineAnnealingWarmupRestarts\n",
    "import loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path = './ckpt'\n",
    "exp_name = 'PFNet'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "args = {\n",
    "    'epoch_num': 300,\n",
    "    'train_batch_size': 32,\n",
    "    'last_epoch': 0,\n",
    "    'lr': 1e-4, \n",
    "    'lr_decay': 0.9,\n",
    "    'weight_decay': 5e-4,\n",
    "    'momentum': 0.9,\n",
    "    'snapshot': '',\n",
    "    'scale': 416, \n",
    "    'save_point': [],\n",
    "    'poly_train': False,\n",
    "    'optimizer': 'Adam',\n",
    "    'amp' : False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        inputs = F.sigmoid(inputs) # sigmoid를 통과한 출력이면 주석처리\n",
    "        \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.reshape(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.0*intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice \n",
    "\n",
    "dice_loss = DiceLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dice_loss(pred, target, smooth = 1.):\n",
    "#     pred = pred.contiguous()\n",
    "#     target = target.contiguous()\n",
    "#     intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "#     loss = (1 -   ( (2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth))  )\n",
    "#     return loss.mean()\n",
    "\n",
    "\n",
    "# def soft_dice_loss(inputs, targets):\n",
    "#         num = targets.size(0)\n",
    "#         m1  = inputs.view(num,-1)\n",
    "#         m2  = targets.view(num,-1)\n",
    "#         intersection = (m1 * m2)\n",
    "#         score = 2. * (intersection.sum(1)+1) / (m1.sum(1) + m2.sum(1)+1)\n",
    "#         score = 1 - score.sum()/num\n",
    "#         return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SA_Unet import SA_UNet\n",
    "\n",
    "net = SA_UNet(in_channels=3, num_classes=2 , base_c=16)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=args['lr'])\n",
    "scheduler = CosineAnnealingWarmupRestarts(optimizer, first_cycle_steps=50, cycle_mult=1.0, max_lr=1e-3, min_lr=1e-5, warmup_steps=5, gamma=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making data index list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_files = os.walk(\"/home/sklab2/workspace/datashared/SS-OCT/vessel_segmentation/masked\")\n",
    "mask_idx = []\n",
    "for (root, dirs, files) in mask_files:\n",
    "    if len(files) > 0 :\n",
    "        mask_idx.append(files)\n",
    "\n",
    "mask_idxs = [element for array in mask_idx for element in array]\n",
    "len(mask_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1~ 11 / 12, 13, 14  , 40, 41, 43, 44, 46, 49,  50, 53, 54, 55 \n",
    "train_indexs = []\n",
    "test_indexs = []\n",
    "for idx, data in enumerate(mask_idxs):\n",
    "    tmp = mask_idxs[idx].split('_')\n",
    "    if len(tmp) < 3:\n",
    "        if int(tmp[0]) < 45:\n",
    "            train_indexs.append([ tmp[0], tmp[1].split('.')[0]])\n",
    "        else:\n",
    "            test_indexs.append([tmp[0], tmp[1].split('.')[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_indexs) , len(test_indexs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations.augmentations.functional as AF\n",
    "\n",
    "PATH = '/home/sklab2/workspace/datashared/SS-OCT/vessel_segmentation/'\n",
    "class VesselDataset(Dataset):\n",
    "    def __init__(self, index, transforms):\n",
    "        self.index = index\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        s_1 = self.index[idx][0]\n",
    "        s_2 = self.index[idx][1]\n",
    "\n",
    "        # '1_L_0.jpg', \n",
    "        # image = Image.open(PATH+'origin/' + s_1+'_L_'+s_2+'.jpg').convert(\"L\").resize((416, 416),Image.Resampling.BILINEAR)\n",
    "        image = Image.open(PATH+'origin/' + s_1+'_L_'+s_2+'.jpg').resize((416, 416),Image.Resampling.BILINEAR)\n",
    "        #'10_L_112_L.png', \n",
    "        mask = Image.open(PATH+'masked/' +  s_1+'_'+s_2+'.png').resize((416, 416),Image.Resampling.BILINEAR)\n",
    "        \n",
    "        image = np.array(image, dtype=np.uint8) #RGB\n",
    "        mask = np.array(mask, dtype=np.uint8)   # HWC\n",
    "        # mask_o = mask / 255        # CHW\n",
    "        mask_o = mask.transpose(2, 0, 1)\n",
    "        lower_red = np.array([-10, 100, 100]) \n",
    "        upper_red = np.array([10, 255, 255])\n",
    "\n",
    "        lower_yellow = np.array([22, 93, 0]) \n",
    "        upper_yellow = np.array([45, 255, 255])\n",
    "\n",
    "        # lower_yellow = np.array([55, 60, 200]) \n",
    "        # upper_yellow = np.array([60, 255, 255]) \n",
    "\n",
    "        mask_hsv = cv2.cvtColor(mask, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        mask_r = cv2.inRange(mask_hsv, lower_red, upper_red)\n",
    "        mask_y = cv2.inRange(mask_hsv, lower_yellow, upper_yellow)\n",
    "        # mask_y = 255 - mask_y # 색반전\n",
    "        mask_r = mask_r/255\n",
    "        mask_y = mask_y/255\n",
    "\n",
    "        mask_r = np.clip(mask_r, 0 ,1)\n",
    "        mask_y = np.clip(mask_y, 0, 1)\n",
    "\n",
    "        mask_r = np.expand_dims(mask_r,axis=0)\n",
    "        mask_y = np.expand_dims(mask_y,axis=0)\n",
    "\n",
    "        # mask = np.concatenate([mask_r, mask_y], axis=0)\n",
    "        masks = [mask_r, mask_y]\n",
    "        # print(mask.shape)\n",
    "    \n",
    "        # aft_mask = cv2.resize(aft_mask, (416, 416), interpolation=cv2.INTER_NEAREST)\n",
    "        # for num in range(3): #### 3번 이터레이션이 왜들어갔지?\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image, masks=masks)\n",
    "            image, masks = transformed['image'], transformed['masks']\n",
    "\n",
    "        mask = np.concatenate([masks[0], masks[1]], axis=-3)\n",
    "        mask = torch.from_numpy(mask).type(torch.LongTensor)\n",
    "        \n",
    "        # urls.append(s_1+'_'+s_2)\n",
    "        # assert sum(masks[0]==0).sum() + sum(masks[0]==1).sum() == 416*416   # mask가 0 또는 1이 아닐경우 스탑\n",
    "                    \n",
    "        return image, mask, mask_o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations.pytorch as AP\n",
    "\n",
    "train_transforms = A.Compose([\n",
    "    # A.RandomRotate90(p=0.25),\n",
    "    A.HorizontalFlip(p=0.25),\n",
    "    A.VerticalFlip(p=0.25),\n",
    "    A.OneOf([\n",
    "        A.OpticalDistortion(p=1, distort_limit=0.1, interpolation=cv2.INTER_LINEAR),\n",
    "        A.GridDistortion(p=1, interpolation=cv2.INTER_LINEAR),\n",
    "        A.ElasticTransform(p=1, interpolation=cv2.INTER_LINEAR),\n",
    "        ], p = 0.5),  # 밝기 및 조도 변화\n",
    "    # A.Normalize(mean=(126.71482973095203, 126.6879562017254, 126.85466873988524), std = (32.9434, 33.0122, 32.9186)),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n",
    "    AP.ToTensorV2(transpose_mask=False),\n",
    "])\n",
    "\n",
    "test_transforms = A.Compose([\n",
    "    AP.ToTensorV2(transpose_mask=False)\n",
    "])\n",
    "\n",
    "train_dataset = VesselDataset(index=train_indexs, transforms=train_transforms)\n",
    "test_dataset = VesselDataset(index=test_indexs, transforms=test_transforms)\n",
    " \n",
    "#train_dataset, _, test_dataset = torch.utils.data.random_split(dataset, [train, 0, test])\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=args['train_batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# image, [mask_r, mask_y, mask_o] =next(iter(train_loader))\n",
    "image, mask, mask_o = next(iter(train_loader))\n",
    "print(image.shape, mask.shape, mask_o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score, precision_score, recall_score\n",
    "def calc_metric(labels, preds):\n",
    "    accuracy = np.mean(np.equal(labels,preds))\n",
    "    right = np.sum(labels *preds == 1)\n",
    "    precision = right / np.sum(preds)\n",
    "    recall = right / np.sum(labels)\n",
    "    f1 = 2 * precision*recall/(precision+recall)\n",
    "\n",
    "    \n",
    "    y_pred = preds\n",
    "    y_true = labels\n",
    "    \"\"\" Ground truth \"\"\"\n",
    "    #y_true = y_true.cpu().numpy()\n",
    "    y_true = y_true > 0.5\n",
    "    y_true = y_true.astype(np.uint8)\n",
    "    y_true = y_true.reshape(-1)\n",
    "\n",
    "    \"\"\" Prediction \"\"\"\n",
    "    #y_pred = y_pred.cpu().numpy()\n",
    "    y_pred = y_pred > 0.5\n",
    "    y_pred = y_pred.astype(np.uint8)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    score_jaccard = jaccard_score(y_true, y_pred)\n",
    "\n",
    "    print('jaccard, f1, recall, precision, acc')\n",
    "    print(score_jaccard, f1, recall, precision, accuracy)\n",
    "    return score_jaccard, f1, recall, precision, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_pil_image(torchvision.utils.make_grid(image[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_pil_image(torchvision.utils.make_grid(mask_o[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_pil_image(torchvision.utils.make_grid(mask[:5, 0].unsqueeze(-3).expand(5, 3, 416, 416).type(torch.float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF.to_pil_image(torchvision.utils.make_grid(mask[:5, 1].unsqueeze(-3).expand(5, 3, 416, 416).type(torch.float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net(image.float()).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import DefaultDict\n",
    "from sklearn.exceptions import DataDimensionalityWarning\n",
    "from tensorboardX import SummaryWriter\n",
    "import datetime \n",
    "\n",
    "exp = 'SA-UNet_2class+aug+coslr'\n",
    "\n",
    "num_epochs = args['epoch_num']\n",
    "resume_epochs = args['last_epoch']\n",
    "load_from = '../model/vessel_PFNet_base_b32_e500_220921_00:30.pt'\n",
    "\n",
    "\n",
    "batch_size = args['train_batch_size']\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "now = datetime.datetime.now()\n",
    "log_name = f'{exp}_b{batch_size}_e{num_epochs}_js_'+now.strftime(\"%y%m%d_%H:%M\")\n",
    "writer = SummaryWriter(log_dir='./ckpt/PFNet/log/'+ log_name)\n",
    "save_path = f'../model/vessel_{exp}_b{batch_size}_e{num_epochs}_'+ now.strftime(\"%y%m%d_%H:%M\") + '.pt'\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f'Using {torch.cuda.device_count()} GPUs.')\n",
    "    \n",
    "net = nn.DataParallel(net)\n",
    "\n",
    "# net.float()\n",
    "net = net.to(device)\n",
    "train_loss_list = []\n",
    "test_acc_list = []\n",
    "test_recall_list = []\n",
    "test_f1_list = []\n",
    "test_miou_list = []\n",
    "print(log_name)\n",
    "print(save_path)\n",
    "print(f'Training {num_epochs} epochs.')\n",
    "if resume_epochs != 0:\n",
    "    print(f'Resuming from epoch {resume_epochs}')\n",
    "    net.load_state_dict(torch.load(load_from))\n",
    "if args['amp'] == True:\n",
    "    print(\"Using mixed precision.\")\n",
    "\n",
    "# print(data.shape, aug_masks[0].shape, aug_masks[1].shape, aft_mask.shape)\n",
    "curr_iter = 1\n",
    "\n",
    "for epoch in range(args['last_epoch'], args['last_epoch'] + args['epoch_num']):\n",
    "    \n",
    "    net.train()\n",
    "\n",
    "    loss_running = 0\n",
    "    tqdm_dataset = tqdm(train_loader)\n",
    "    for batch_idx, batch in enumerate(tqdm_dataset):\n",
    "        if args['poly_train']:\n",
    "            base_lr = args['lr'] * (1 - float(curr_iter) / float(num_epochs)) ** args['lr_decay']\n",
    "            optimizer.param_groups[0]['lr'] = 2 * base_lr\n",
    "            optimizer.param_groups[1]['lr'] = 1 * base_lr\n",
    "        # label: ([32, 2, 416, 416])\n",
    "        image, mask, _= batch\n",
    "        image = image.float().to(device)\n",
    "        mask = mask.long().to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred = net(image)\n",
    "        loss = dice_loss(pred, mask)\n",
    "        # loss = loss_r + 0.5 * loss_y\n",
    "        # loss = loss_r + 0.2*loss_y\n",
    "        # loss = loss_r\n",
    "        \n",
    "        loss.backward()\n",
    "        # nn.utils.clip_grad_norm_(net.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_running += loss.item()\n",
    "        \n",
    "        tqdm_dataset.set_postfix({\n",
    "            'Epoch': epoch,\n",
    "            'Loss': '{:06f}'.format(loss.item()),\n",
    "            'Mean Loss' : '{:06f}'.format(loss_running/(batch_idx+1)),\n",
    "            'lr' : '{:06f}'.format(optimizer.param_groups[0][\"lr\"])\n",
    "        })\n",
    "\n",
    "        curr_iter += 1\n",
    "\n",
    "    epoch_loss = loss_running / len(train_loader)\n",
    "\n",
    "    writer.add_scalar('loss/Train', epoch_loss, epoch)\n",
    "    writer.add_scalar('learning_rate', optimizer.param_groups[0][\"lr\"], epoch)\n",
    "    train_loss_list.append(epoch_loss)\n",
    "    scheduler.step()\n",
    "\n",
    "## EVAL\n",
    "    if epoch % 10 == 0 or epoch == args['epoch_num']-1 :\n",
    "        print(\"Testing...\")\n",
    "\n",
    "        images=[]\n",
    "        preds=[]\n",
    "        masks=[]\n",
    "        mask_os = []\n",
    "        \n",
    "        net.eval()\n",
    "        # tqdm_loader = tqdm(test_loader)\n",
    "        with torch.no_grad():\n",
    "            loss_running = 0\n",
    "            for idx, batch in enumerate(tqdm(test_loader)):\n",
    "\n",
    "                image, mask, mask_o= batch\n",
    "                image = image.float().to(device)\n",
    "                mask = mask.long().to(device)\n",
    "                pred = net(image)\n",
    "                \n",
    "                loss = dice_loss(pred, mask)\n",
    "                # loss_r = dice_loss(pred[:, 0], mask[:, 0])\n",
    "                # loss_y = dice_loss(pred[:, 1], mask[:, 1])\n",
    "\n",
    "                # loss = loss_r + 0.5 * loss_y\n",
    "                loss_running += loss.item()\n",
    "\n",
    "                images.append(image.cpu().detach().numpy())\n",
    "                masks.append(mask.cpu().detach().numpy())   # B, 3, 416, 416\n",
    "                preds.append(pred.cpu().detach().numpy())\n",
    "                mask_os.append(mask_o)\n",
    "\n",
    "            images= np.array(images)#.squeeze(1)\n",
    "            # preds = np.expand_dims(np.array(preds)[:, 0], axis=1)\n",
    "            masks = np.array(masks).squeeze(1)\n",
    "            preds = np.array(preds).squeeze(1)\n",
    "            \n",
    "            preds = np.where(preds > 0.5 , 1 , 0)\n",
    "            masks = np.where(masks > 0.5, 1, 0)\n",
    "            mask_os = np.array(mask_os)\n",
    "            epoch_loss = loss_running / len(test_loader)\n",
    "            print(f\"Test loss: {epoch_loss}\")\n",
    "\n",
    "            assert preds.shape == masks.shape\n",
    "            # 빨간색 라벨만 계산\n",
    "            score_jaccard, score_f1, score_recall, score_precision, score_acc = calc_metric(labels=masks[:, 0], preds=preds[:, 0])\n",
    "            \n",
    "            test_acc_list.append(score_acc)\n",
    "            test_recall_list.append(score_recall)\n",
    "            test_f1_list.append(score_f1)\n",
    "            test_miou_list.append(score_jaccard)\n",
    "\n",
    "            writer.add_scalar('loss/Test', epoch_loss, epoch)\n",
    "            writer.add_scalar('Accuracy/Test', score_acc, epoch)\n",
    "            writer.add_scalar('F1/Test', score_f1, epoch)\n",
    "            writer.add_scalar('Recall/Test', score_recall, epoch)\n",
    "            writer.add_scalar('Precision/Test', score_precision, epoch)\n",
    "            writer.add_scalar('Jaccard/Test', score_jaccard, epoch)\n",
    "\n",
    "            if np.max(test_miou_list) == test_miou_list[-1]:\n",
    "                torch.save(net.state_dict(), save_path)\n",
    "                print(\"Model Saved\")\n",
    "\n",
    "            randnum = np.random.randint(0, 171)\n",
    "            plt.figure(figsize=(16, 4))\n",
    "            plt.subplot(1, 4, 1)  \n",
    "            plt.imshow(mask_os[randnum][0].permute(1, 2, 0))\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 4, 2)  \n",
    "            plt.imshow(masks[randnum][0])\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 4, 3)\n",
    "            plt.imshow(masks[randnum][1])\n",
    "            plt.axis('off')\n",
    "            plt.subplot(1, 4, 4)\n",
    "            plt.imshow(preds[randnum][0])\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = preds.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(preds).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(image.float()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net(image.float()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, [mask_r, mask_y], mask_o = next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(preds).squeeze(2)[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing...\")\n",
    "net = SA_UNet(in_channels=3, num_classes=2 , base_c=16)\n",
    "load_from = '/home/sklab2/workspace/code_only/junsu/model/vessel_SA-UNet_2lb_base_b32_e300_221002_12:16.pt'\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f'Using {torch.cuda.device_count()} GPUs.')\n",
    "net = nn.DataParallel(net)\n",
    "net.load_state_dict(torch.load(save_path))\n",
    "net.to(device)\n",
    "\n",
    "images=[]\n",
    "preds=[]\n",
    "labels=[]\n",
    "label_os = []\n",
    "net.eval()\n",
    "# tqdm_loader = tqdm(test_loader)\n",
    "with torch.no_grad():\n",
    "    loss_running = 0\n",
    "    for idx, batch in enumerate(tqdm(test_loader)):\n",
    "\n",
    "        image, mask, mask_o= batch\n",
    "        image = image.float().to(device)\n",
    "        mask = mask.long().to(device)\n",
    "        pred = net(image)\n",
    "        \n",
    "        loss = dice_loss(pred, mask)\n",
    "        # loss_r = dice_loss(pred[:, 0], mask[:, 0])\n",
    "        # loss_y = dice_loss(pred[:, 1], mask[:, 1])\n",
    "\n",
    "        # loss = loss_r + 0.5 * loss_y\n",
    "        loss_running += loss.item()\n",
    "\n",
    "        images.append(image.cpu().detach().numpy())\n",
    "        masks.append(mask.cpu().detach().numpy())   # B, 3, 416, 416\n",
    "        preds.append(pred.cpu().detach().numpy())\n",
    "        mask_os.append(mask_o)\n",
    "\n",
    "    images= np.array(images)#.squeeze(1)\n",
    "    # preds = np.expand_dims(np.array(preds)[:, 0], axis=1)\n",
    "    masks = np.array(masks).squeeze(1)\n",
    "    preds = np.array(preds).squeeze(1)\n",
    "    \n",
    "    preds = np.where(preds > 0.5 , 1 , 0)\n",
    "    masks = np.where(masks > 0.5, 1, 0)\n",
    "    mask_os = np.array(mask_os)\n",
    "    epoch_loss = loss_running / len(test_loader)\n",
    "    print(f\"Test loss: {epoch_loss}\")\n",
    "\n",
    "    assert preds.shape == masks.shape\n",
    "    # 빨간색 라벨만 계산\n",
    "    score_jaccard, score_f1, score_recall, score_precision, score_acc = calc_metric(labels=masks[:, 0], preds=preds[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# randnum = np.random.randint(0, len(test_dataset)-10)\n",
    "randnum=211\n",
    "\n",
    "fig, axes = plt.subplots(10, 3, figsize = (10,40))\n",
    "[c_ax.axis('off') for c_ax in axes.flatten()]\n",
    "\n",
    "for idx, (img_ax, target_ax , mask_ax ) in zip(range(randnum, randnum+10), axes):\n",
    "    \n",
    "# inputs[:10] , preds[:10], targets[:10], urls_list[:10]) :\n",
    "    \n",
    "    image = images[idx].astype(int).transpose(1, 2, 0) # astype(int)\n",
    "    img_target = preds[idx].transpose(1, 2, 0) \n",
    "    img_mask = labels[idx].transpose(1, 2, 0)  \n",
    " \n",
    "    img_ax.imshow(np.clip(image, 0, 255))\n",
    "\n",
    "    target_ax.imshow(img_target )\n",
    "    mask_ax.imshow(img_mask)\n",
    "\n",
    "    img_ax.set_title(f'  testing: {idx}')\n",
    "    target_ax.set_title(f' Predicted : {idx}')\n",
    "    \n",
    "    mask_ax.set_title(f' target   vessel: {idx}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8128ea53b667df2c63505870f2ff8004b9270a6bef27cafea1d8458469672f96"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
